---
title: "Devoir sur les Tests Statistiques"
author: "KANE Seydou, DIALLO Malick Toussaint, LOUCAR   Khadime"
date: "21 décembre 2020"
output: html_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Test statistique:

Un test statistique est une procédure qui vise à apporter une réponse à la question :
Est-ce que les données nous permettent de rejeter H0, donc d’accepter H1, avec un faible risque de se tromper ?

La p-valeur est le plus petit réel $α \in]0, 1[$ calculé à partir des données tel que l’on puisse se permettre de rejeter $H0$ . Dans toute la partie, nous avons fixé le seuil $\alpha$ à 0.05.

## Tests de conformité à une valeur de référence

##  Exemple 1: Bilateral

Nos supposons observer la valeur de $X ∼ N (µ, σ2)$ pour chacun des n individus (composants) d’un échantillon avec n = 24, µ inconnu et σ = 0.38. On considère l’hypothèse suivante:\par
$$<<H0 : µ = 7.3>>   \text{contre}   <<H1 : µ \neq 7.3.>>$$
```{r}
#install.packages("OneTwoSamples")

library(OneTwoSamples)
X = c(6.47, 7.02, 7.15, 7.22, 7.44, 6.99, 7.47, 7.61, 7.32, 7.22, 7.52,
6.92, 7.28, 6.69, 7.24, 7.19, 6.97, 7.52, 6.22, 7.13, 7.32, 7.67, 7.24,
6.21)

mean_test1(X, 7.3, 0.38)

```

Dans cet exemple le p-value vaut   Comme p-valeur $\in ]0.01, 0.05]$, le rejet de H0 est significatif.

##  Exemple 2: Unilateral 

Nos supposons observer la valeur de $ X ∼ N (µ, σ2) $ pour chacun des n individus (composants) d’un échantillon avec n = 12,  µ et σ  inconnus. On considère l’hypothèse suivante:\par
$$<<H0 : µ \leq   10 >>   \text{contre}   <<H1 : µ >  10 >>$$

```{r}
x = c(10.1, 9.8, 10.2, 10.3, 10.4, 9.8, 9.9, 10.4, 10.2, 9.5, 10.4, 9.6)
t.test(x, mu = 10, alternative = "greater")

```


Comme p-valeur > 0.05, on ne rejette pas $H_0$

##  Exemple 3: Bilateral 

Nos supposons observer la valeur de $X ∼ N (µ, σ2) $ pour chacun des n individus (composants) d’un échantillon avec n = 8,  µ et σ  inconnus. On considère l’hypothèse suivante:\par
$$<<H0 : µ = 276  >>   \text{contre}   <<H1 : µ \neq 276 >>$$




```{r}
X = c(232, 277, 235, 245, 245, 250, 268, 256)
t.test(X, mu = 276)$p.value

```

Cela renvoie un p-valeur 0.00259146 $\in]0.001, 0.01]$, le rejet de H0 est très significatif.

## Exemple 4: Bilateral

Soit $X ∼ B(p)$, Nous allons simuler n=400 observation suivant la loi de Bernoulli de paramètre p, Ainsi on considère les hypothèses:
$$<<H0 : p = 0.25  >>   \text{contre}   <<H1 : 0\neq 0.25 >>$$

```{r}
set.seed(300)
n<-400
X<-rbinom(n,1,0.25)
nb_succes<- sum(X)
#nb_succes
binom.test(nb_succes, 400, 0.25)$p.value

```


Comme p-valeur > 0.05, on ne rejette pas $H_0$

## 2. Tests d’homogénéité : échantillons indépendants
## Exemple 1:
Soient $X_1$ et $X_2$ deux échantillons telsque $X_1 ∼ N (µ_1, 1.3^2)$ et $X_2 ∼ N (µ_2, 0.9^2)$, nous allons considerer les hypothèses suivantes pour effectuer le test:  

$$<<H0 : \mu_1 = \mu_2  >>   \text{contre}   <<\mu_1 \neq \mu_2  >>$$

```{r}
x1 = c(106.70, 107.02, 107.15, 107.22, 107.41, 106.39, 107.47, 107.61,
107.38, 107.22)
x2 = c(107.68, 106.69, 107.24, 107.69, 106.97, 107.52, 106.22, 107.23,
107.32)

mean_test2(x1, x2, sigma = c(1.3, 0.9))$p_value


```

Comme p-valeur > 0.05, on ne rejette pas H0.

## Exemple 2:

Nous considerer l'exemple 1 de sorte que$X_1 ∼ N (µ_1, \sigma_2^2)$ et $X_2 ∼ N (µ_2, \sigma_2^2)$ avec $\mu_1,\mu_2,\sigma_1 et \sigma_2$ inconnus, mais connaissant que $\sigma_1^2 = \sigma_2^2$ :

```{r}
x1 = c(31.70, 31.98, 32.24, 32.35, 31.18, 32.19, 32.63, 31.19, 31.54, 31.89)
x2 = c(31.61, 31.10, 31.20, 31.11, 32.66, 31.15, 31.71, 31.22, 31.16, 31.21)

t.test(x1, x2, var.equal = T)$p.value


```

Comme p-valeur $\in]0.01, 0.05]$, le rejet de H0 est significatif.
Ainsi, on peut affirmer que les deux échantillons proviennent de deux productions différentes. 

```{r}

```

## Exemple 3:

Nous considerer l'exemple 2 de sorte que$X_1 ∼ N (µ_1, \sigma_2^2)$ et $X_2 ∼ N (µ_2, \sigma_2^2)$ avec $\mu_1,\mu_2,\sigma_1 et \sigma_2$ inconnus, mais sans connaissance de l'égalité $\sigma_1^2 = \sigma_2^2$ :

```{r}
x1 = c(12.12, 12.03, 13.58, 13.38, 11.81, 15.92, 13.65)
x2 = c(14.81, 13.93, 14.91, 15.87, 15.62, 15.39)
t.test(x1, x2)$p.value

```

Comme p-valeur $\in]0.01, 0.05]$, le rejet de H0 est significatif.

## Exemple 4:
Soient $X_1 ∼ B(p_1)$, de $n_1=230$ observations et $X_1 ∼ B(p_1)$, de $n_2=340$ observations, Ainsi on considère les hypothèses suivantes pour faire le test:
$$<<H0 : p_1 \leq p_2  >>   \text{contre}   <<H1 : p_1 >p_2 >>$$

```{r}
n1<-230
n2<-340
nb_1_suc<-54
nb_2_suc<-110
prop.test(x = c(nb_1_suc, nb_2_suc), n = c(n1, n2), alternative = "less")

```

Comme p-valeur $\in ]0.01, 0.05]$, le rejet de H0 est significatif.

## Tests d’indépendance entre deux caractères

On observe la valeur de (X, Y ) pour chacun des n individus (familles) d’un échantillon de taille n. On considère les hypothèses:

H0 : "les caractères X et Y sont indépendants" contre
H1 : "les caractères X et Y ne sont pas indépendants".

On utilise le test de nullité du coefficient de corrélation.

```{r}
x = c(121, 142, 108, 111, 97, 139, 131, 90, 115, 107, 124, 103, 115, 151)
y = c(102, 138, 126, 133, 95, 146, 115, 100, 142, 105, 130, 120, 109, 123)

plot(x, y)

```

#### En  admettant l’hypothèse de normalité sur la loi de (X, Y ).
On a: 

```{r}
cor.test(x, y)$p.value


```

Comme p-valeur $\in ]0.01, 0.05]$, le rejet de H0 est significatif.
#### En cas de non normalité:
Nous allons étudier l’indépendance de X et Y en faisant le test de nullité du coefficient de corrélation de Spearman dans l'exemple suivant:

```{r}
x1 = c(13.12, 13.54, 15.12, 14.51, 12.12, 13.10, 13.98, 11.21, 14.44)
x2 = c(13.92, 13.89, 14.51, 14.78, 10.97, 13.58, 14.52, 11.54, 13.54)
cor.test(x1, x2, method = "spearman")


```


Comme p-valeur < 0.05, on rejette H0.


## Test de Kolmogorov-Smirnov :

il permet de tester si un échantillon suit une loi donnée.
Tester si deux échantillons suivent la même loi (pas seulement de même moyenne, mais aussi de même variance, etc ...)

Soit $X_1$,...,$X_n$ un échantillon et $F_0$ une distribution donnée. On cherche à déterminer si l’échantillon est tiré suivant $F$ une distribution connue ou si deux échantillons suivent la même loi. Pour cela, on considère : 

$$H_0: F_n=F_0$$
$$H_1: F_n!=F_0$$.

La statistique est donnée par: 
$$D_n=\max\max|F_{0}(X)-\frac{j-1}{n}|, |F_{0}(X)-\frac{j}{n})|$$

 Nous avons definit une fonction qui réalise le test de kolmogorov-smirnov pour une rélisation de distribution $F_0$ et retourne True si l’hypothèse nulle n’est pas rejetée pour un seuil alpha


```{r}

K_s=function(X){
    d_0.05 = 1.358/sqrt(length(X)) 
    x=sort(X)
    N=length(X)
    S=1:N/N
   z=(x-mean(x))/sd(x)
   F<-pnorm(z,0,1)
   Diff1=abs(S-F)
   Diff2=c(F[1], rep(0,N-1))
   for (i in 2:length(X)){
   Diff2[i]=abs(S[i-1]-F[i])}
  D1=sort(Diff1)
  D2=sort(Diff2)
  n=length(X)
  Dmax=c(D1[length(D1)],D2[length(D2)])
  return(ifelse(max(Dmax)<d_0.05, "True", "False"))
}

```



## Exemple:

 On crée des échantillons a, b et c.
 a est un échantillon de taille 100 issu de la loi normale centré et reduite.
 b est un échantillon de taille 100 issu de la loi de gamma de paramètre 1 et 0.8.
c est un échantillon de taille 50 issu de la loinormale centré et reduite.
 
 
 
```{r}
set.seed(130)
a<-rnorm(100,mean=0,sd=1)
b<-rgamma(100,shape=1,rate=0.8)
c<-rnorm(50,mean=0,sd=1)

K_s(b)
K_s(a)

```

##### a et b proviennent-ils de la même loi?

```{r}
ks.test(a,b)

```

p=1.264e- << 0.05 on rejette l'hypothèse nulle

##### a et c proviennent-ils de la même loi?

```{r}
ks.test(a,c)
```

p=0.9809 >0.05 on accepte l'hypothèse nulle

##### a provient-il d'une loi gamma avec 3 comme paramètre de forme et 2 pour le taux?


```{r}


ks.test(a,"pgamma",3,2)



```

p value très faible on rejette l'hypothèse nulle.

#####a provient-il d'une loi normale?


```{r }
ks.test(a,"pnorm")


```

p=0.13 on accepte l'hypothèse nulle.

## Test de Wilcoxon:

Le test de Wilcoxon (ou de Mann-Whitney) est un test non-paramétrique de comparaison de moyennes de deux échantillons indépendants ou appariés.


```{r}

x <- c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73, 1.46)
y <- c(1.15, 0.88, 0.90, 0.74, 1.21)
wilcox.test(x, y)

```

p=0.2544 > 0.05 donc les deux échantillons x et y ne sont pas significativement différents.




